# -*- coding: utf-8 -*-
"""prediksi komentar .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FpOb5h3fmowGSQ4NaAs5Nc58BVaqwXBK
"""

import pandas as pd
import re
import string
import nltk
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

# 1. Setup Pembersihan Teks dan Stopwords
try:
    stopwords.words('indonesian')
except:
    nltk.download('stopwords')
stop_words = set(stopwords.words('indonesian'))

def preprocess_text(text):
    """Fungsi untuk membersihkan teks dari simbol, tautan, dan stopwords."""
    # Menghilangkan mention (@username) dan hashtag (#tag)
    text = re.sub(r'@[A-Za-z0-9_]+', '', text)
    text = re.sub(r'#\w+', '', text)
    # Menghilangkan tautan (URL)
    text = re.sub(r'http\S+|www\.\S+', '', text)
    # Menghilangkan karakter selain huruf dan angka
    text = re.sub(r'[^a-zA-Z0-9\s]', ' ', text)
    # Mengubah ke huruf kecil
    text = text.lower()
    # Menghilangkan stopwords
    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

def train_and_save_model(file_path):
    """Melatih model klasifikasi dari data training."""

    # Memuat data (menggunakan delimiter ';' sesuai struktur file)
    try:
        df = pd.read_csv(file_path, delimiter=';')
    except Exception as e:
        print(f"Error saat memuat file: {e}")
        return None, None

    # Memastikan kolom yang dibutuhkan ada
    if 'full_text' not in df.columns or 'labels' not in df.columns:
        print("Pastikan file memiliki kolom 'full_text' dan 'labels'.")
        return None, None

    # Pembersihan teks
    df['clean_text'] = df['full_text'].apply(preprocess_text)

    # Mendefinisikan fitur (X) dan target (y)
    X = df['clean_text']
    y = df['labels']

    # Membuat Pipeline untuk Vektorizer dan Classifier
    # Model: Logistic Regression
    text_classifier = Pipeline([
        ('tfidf', TfidfVectorizer()),
        ('classifier', LogisticRegression(random_state=42, max_iter=1000))
    ])

    # Melatih model
    print("Mulai melatih model...")
    text_classifier.fit(X, y)
    print("Pelatihan model selesai.")

    # (Opsional) Evaluasi model di data training untuk melihat performa awal
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    text_classifier.fit(X_train, y_train)
    predictions = text_classifier.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    print("\n--- Akurasi: ", accuracy)
    print("---\n--- Laporan Klasifikasi (di Data Uji) ---")
    print(classification_report(y_test, predictions, target_names=['0 (Opini/Kritik)', '1 (Informasi)', '2 (Aksi/Bantuan)'], zero_division=0))

    return text_classifier

def classify_new_comment(model, new_texts):
    """Menggunakan model yang telah dilatih untuk memprediksi label komentar baru."""

    if model is None:
        print("Model tidak tersedia untuk prediksi.")
        return

    # Mapping Label
    label_map = {
        0: "0 (Opini/Keluhan/Kritik)",
        1: "1 (Informasi)",
        2: "2 (Aksi Pemerintah/Bantuan)"
    }

    # Memproses dan memprediksi
    print("\n--- Hasil Prediksi Komentar Terbaru ---")
    predictions = model.predict(new_texts)

    for text, label in zip(new_texts, predictions):
        print(f"\n[Komentar]: '{text}'")
        print(f"[Prediksi]: {label_map.get(label, 'Label Tidak Dikenal')}")

# --- Bagian Utama Program ---
if __name__ == "__main__":

    # 1. Path file data training Anda
    data_file = 'dataset_komentarbencana.csv'

    # 2. Melatih model
    classifier_model = train_and_save_model(data_file)

    # 3. Data Komentar Terbaru (yang ingin Anda klasifikasikan)
    new_comments = [
        "Banjir masih setinggi lutut",
        "Menurut saya hujan ini tidak akan berhenti sampai pagi",
        "Tim SAR berhasil mengevakuasi 50 warga yang terjebak banjir di perumahan Kemang Pratama tadi malam. #GerakCepat",
        "Bantuan yang diberikan tentara telah tiba",
        "pekerjaan dan gerak dari tim sar sangat lambat, saran saya perbaiki"
    ]

    # 4. Melakukan Klasifikasi
    if classifier_model:
        classify_new_comment(classifier_model, new_comments)